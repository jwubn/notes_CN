{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "# from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "# import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def clean_data(iStocks):\n",
    "    ##Iterate through stocks\n",
    "    print(\"Processing \" + stocks_tw[iStocks])\n",
    "\n",
    "    ###load stock tick data (gzip)\n",
    "    file1Path = stockDataDir + stocks_tw[iStocks] + '_md_201801_201812.csv.gz'\n",
    "    file2Path = stockDataDir + stocks_tw[iStocks] + '_md_201901_201903.csv.gz'\n",
    "    if os.path.exists(file1Path):\n",
    "        df = pd.read_csv(file1Path, compression='gzip', usecols = cols)\n",
    "        print('Data(First file) for ' + stocks_tw[iStocks] + ' loaded.')\n",
    "\n",
    "        if os.path.exists(file2Path):\n",
    "            df1 = pd.read_csv(file2Path, compression='gzip', usecols = cols)\n",
    "            print('Data(Second file) for ' + stocks_tw[iStocks] + ' loaded.')\n",
    "\n",
    "            df = df.append(df1)\n",
    "    elif os.path.exists(file2Path):\n",
    "        df = pd.read_csv(file2Path, compression='gzip', usecols = cols)\n",
    "        print('Data(Second file) for ' + stocks_tw[iStocks] + ' loaded.')\n",
    "    else:\n",
    "        print('Skipping snapshots data for ' + stocks_tw[iStocks] + '.')\n",
    "#         continue\n",
    "    df=df[df['SP1']>0]\n",
    "    df=df[df['BP1']>0]\n",
    "    df=df[df['SP1']-df['BP1']>0]\n",
    "    df.index = pd.to_datetime(df['date'], format='%Y-%m-%d') - pd.to_datetime('1900', format='%Y') + pd.to_datetime(df['time'].astype(str).str.slice(0, -5), format='%H%M')\n",
    "    df['lastPx'] = df['lastPx'] / 100\n",
    "    df['size'] = df['size'] * 1000\n",
    "    df['volume'] = df['volume'] * 1000\n",
    "    data=pd.DataFrame(columns=['nexttick_px','nexttick_size','close','open','high','low','size'],index=df.index)\n",
    "    data['nexttick_px']=df['lastPx'].shift(-1)\n",
    "    data['nexttick_size']=df['size'].shift(-1)\n",
    "#     data['nexttick_px']=data['nexttick_px'].fillna(axis=0,method='ffill')\n",
    "#     data['nexttick_size']=data['nexttick_size'].fillna(0)\n",
    "    data=data.resample('min').first()\n",
    "    data['close']=df['lastPx'].resample('min').last()\n",
    "    data['close'] = data['close'].shift(1)\n",
    "    data['open']=df['lastPx'].resample('min').first()\n",
    "    data['high']=df['lastPx'].resample('min').max()\n",
    "    data['low']=df['lastPx'].resample('min').min()\n",
    "    data['size']=df['size'].resample('min').sum()\n",
    "    data[['nexttick_px', 'close', 'open', 'high', 'low']]=data[['nexttick_px', 'close', 'open', 'high', 'low']].fillna(method='ffill')\n",
    "    data[['size','nexttick_size']]=data[['size','nexttick_size']].fillna(0)\n",
    "    data.index=pd.to_datetime(data.index)\n",
    "    data=data.between_time('9:00','13:25')\n",
    "#     data.to_csv('2327_5mins.csv')\n",
    "    return (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(close,open,high,low,size):\n",
    "    \"\"\"  \n",
    "    n = parameter for momentum\n",
    "    alpha = decaying parameter for exponential moving average, 0 < alpha <=1\n",
    "    \"\"\"\n",
    "    n = 1\n",
    "    alpha = 0.01\n",
    "    close = close.resample('5min').last()\n",
    "    close = close.fillna(method='ffill')\n",
    "    close = close.between_time('9:00','13:25')\n",
    "    temp=pd.concat([close.index.to_series(name='date').astype(str).str.slice(start=0,stop=10),close],axis=1)\n",
    "    temp['mom'] = temp.close.diff(n)\n",
    "    temp['ema'] = temp.groupby('date')['mom'].apply(lambda col: col.ewm(alpha=alpha).mean())\n",
    "\n",
    "    signal = pd.Series(0, index=close.index)\n",
    "    signal[(temp.mom.shift(1) <= temp.ema) & (temp.mom > temp.ema)] = 1\n",
    "    signal[(temp.mom.shift(1) >= temp.ema) & (temp.mom < temp.ema)] = -1\n",
    "    \n",
    "    for i in range(1, len(signal), 1):\n",
    "        if signal[i] == 0:\n",
    "            signal[i] = signal[i-1]\n",
    "    #reset the first n signals of every day to 0 to avoid the interday effect\n",
    "    for i in np.unique(close.index.date):\n",
    "        signal[str(i)][:n] = 0 \n",
    "    \n",
    "    signal = signal.resample('1min').asfreq()\n",
    "    signal = signal.fillna(method='ffill')\n",
    "    signal = signal.between_time('9:00','13:25')\n",
    "    \n",
    "    return signal\n",
    "\n",
    "def Ichimuku_ver1a(close,open,high,low,size):\n",
    "    \"\"\"  \n",
    "    simple version\n",
    "    \"\"\"\n",
    "    n2 = 1\n",
    "    close = close.resample('5min').last()\n",
    "    high = high.resample('5min').max()\n",
    "    low = low.resample('5min').min()\n",
    "    close = close.fillna(method='ffill')\n",
    "    high = high.fillna(method='ffill')\n",
    "    low = low.fillna(method='ffill')\n",
    "    close = close.between_time('9:00','13:25')\n",
    "    high = high.between_time('9:00','13:25')\n",
    "    low = low.between_time('9:00','13:25')\n",
    "    base = (high.rolling(n2).max() + low.rolling(n2).min())/2\n",
    "    \n",
    "    signal=pd.Series(0, index=close.index)\n",
    "    signal[(base.shift(1)>=close.shift(1)) & (base<close)] = 1\n",
    "    signal[(base.shift(1)<=close.shift(1)) & (base>close)] = -1\n",
    "    \n",
    "    for i in range(1, len(signal), 1):\n",
    "        if signal[i] == 0:\n",
    "            signal[i] = signal[i-1]\n",
    "\n",
    "    #reset the first n2 signals of every day to 0 to avoid the interday effect\n",
    "    for i in np.unique(close.index.date):\n",
    "        signal[str(i)][:n2] = 0\n",
    "    \n",
    "    signal = signal.resample('1min').asfreq()\n",
    "    signal = signal.fillna(method='ffill')\n",
    "    signal = signal.between_time('9:00','13:25')\n",
    "    \n",
    "    return signal\n",
    "\n",
    "def Ichimuku_ver1b(close,open,high,low,size):\n",
    "    \"\"\"  \n",
    "    simple version\n",
    "    \"\"\"\n",
    "    n2 = 2\n",
    "    close = close.resample('5min').last()\n",
    "    high = high.resample('5min').max()\n",
    "    low = low.resample('5min').min()\n",
    "    close = close.fillna(method='ffill')\n",
    "    high = high.fillna(method='ffill')\n",
    "    low = low.fillna(method='ffill')\n",
    "    close = close.between_time('9:00','13:25')\n",
    "    high = high.between_time('9:00','13:25')\n",
    "    low = low.between_time('9:00','13:25')\n",
    "    base = (high.rolling(n2).max() + low.rolling(n2).min())/2\n",
    "    \n",
    "    signal=pd.Series(0, index=close.index)\n",
    "    signal[(base.shift(1)>=close.shift(1)) & (base<close)] = 1\n",
    "    signal[(base.shift(1)<=close.shift(1)) & (base>close)] = -1\n",
    "    \n",
    "    for i in range(1, len(signal), 1):\n",
    "        if signal[i] == 0:\n",
    "            signal[i] = signal[i-1]\n",
    "\n",
    "    #reset the first n2 signals of every day to 0 to avoid the interday effect\n",
    "    for i in np.unique(close.index.date):\n",
    "        signal[str(i)][:n2] = 0\n",
    "    \n",
    "    signal = signal.resample('1min').asfreq()\n",
    "    signal = signal.fillna(method='ffill')\n",
    "    signal = signal.between_time('9:00','13:25')\n",
    "    \n",
    "    return signal\n",
    "\n",
    "def Ichimuku_ver2(close,open,high,low,size):\n",
    "    \"\"\"  \n",
    "    strong version\n",
    "    \"\"\"\n",
    "    n1 = 2\n",
    "    n2 = 4\n",
    "    n3 = 5\n",
    "    \n",
    "    close = close.resample('5min').last()\n",
    "    high = high.resample('5min').max()\n",
    "    low = low.resample('5min').min()\n",
    "    close = close.fillna(method='ffill')\n",
    "    high = high.fillna(method='ffill')\n",
    "    low = low.fillna(method='ffill')\n",
    "    close = close.between_time('9:00','13:25')\n",
    "    high = high.between_time('9:00','13:25')\n",
    "    low = low.between_time('9:00','13:25')\n",
    "    \n",
    "    conversion = (high.rolling(n1).max() + low.rolling(n1).min())/2\n",
    "    base = (high.rolling(n2).max() + low.rolling(n2).min())/2\n",
    "    leadingSpanA = (conversion + base) / 2\n",
    "    leadingSpanB = (high.rolling(n3).max() + low.rolling(n3).min())/2\n",
    "    kumo_upper = np.maximum(leadingSpanA, leadingSpanB).shift(n2)\n",
    "    #kumo_upper2 = pd.DataFrame([leadingSpanA, leadingSpanB]).max()\n",
    "    kumo_lower = np.minimum(leadingSpanA, leadingSpanB).shift(n2)\n",
    "    #kumo_lower2 = pd.DataFrame([leadingSpanA, leadingSpanB]).min()\n",
    "    \n",
    "    signal=pd.Series(0, index=close.index)\n",
    "    signal[(base.shift(1)>=close.shift(1)) & (base<close) & (close.shift(1) > kumo_upper)] = 1\n",
    "    signal[(base.shift(1)<=close.shift(1)) & (base>close) & (close.shift(1) < kumo_lower)] = -1\n",
    "    \n",
    "    for i in range(1, len(signal), 1):\n",
    "        if signal[i] == 0:\n",
    "            signal[i] = signal[i-1]\n",
    "    \n",
    "    #reset the first n2+n3 signals of every day to 0 to avoid the interday effect\n",
    "    for i in np.unique(close.index.date):\n",
    "        signal[str(i)][:(n2+n3)] = 0\n",
    "    \n",
    "    signal = signal.resample('1min').asfreq()\n",
    "    signal = signal.fillna(method='ffill')\n",
    "    signal = signal.between_time('9:00','13:25')\n",
    "    \n",
    "    return signal\n",
    "\n",
    "def MACD_1(close,open,high,low,size):\n",
    "    freq = 1\n",
    "    short=4\n",
    "    long=8\n",
    "    n=3\n",
    "    da = close[close.index.minute % freq == 0]\n",
    "    da=pd.concat([da.index.to_series(name='date').astype(str).str.slice(start=0,stop=10),da],axis=1)\n",
    "    short_window=da.groupby('date')['close'].apply(lambda col: col.ewm(span=short//freq, min_periods=short//freq,adjust=False).mean())\n",
    "    long_window=da.groupby('date')['close'].apply(lambda col: col.ewm(span=long//freq, min_periods=long//freq,adjust=False).mean())\n",
    "    macd=short_window-long_window\n",
    "    SignalLine=macd.ewm(span=n/freq,min_periods=n/freq,adjust=False).mean()\n",
    "    macds=macd-SignalLine\n",
    "    signal=pd.Series({}, index=short_window.index)\n",
    "    signal[(macd.shift(1)<=macds)&(macd>macds)]=1\n",
    "    signal[(macd.shift(1)>=macds)&(macd<macds)]=-1\n",
    "    data = pd.concat([signal.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), signal], axis=1)\n",
    "    signal = data.groupby('date')[0].fillna(method='ffill')\n",
    "    signal = signal.fillna(0)\n",
    "    signal = signal.reindex(close.index, method='ffill')\n",
    "    return signal\n",
    "\n",
    "def acceleration_1(close,open,high,low,size):\n",
    "    freq = 1\n",
    "    n=3\n",
    "    da = close[close.index.minute % freq == 0]\n",
    "    da=pd.concat([da.index.to_series(name='date').astype(str).str.slice(start=0,stop=10),da],axis=1)\n",
    "    mom=da.groupby('date')['close'].shift(0)-da.groupby('date')['close'].shift(n//freq)\n",
    "    acc=mom-mom.shift(1)\n",
    "    signal=pd.Series({}, index=mom.index)\n",
    "    signal[(acc.shift(1)<=0)&(acc>0)]=1\n",
    "    signal[(acc.shift(1)>=0)&(acc<0)]=-1\n",
    "    data = pd.concat([signal.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), signal], axis=1)\n",
    "    signal = data.groupby('date')[0].fillna(method='ffill')\n",
    "    signal = signal.fillna(0)\n",
    "    signal = signal.reindex(close.index, method='ffill')\n",
    "    return signal\n",
    "\n",
    "def acceleration_2(close,open,high,low,size):\n",
    "    freq = 1\n",
    "    n=2\n",
    "    da = close[close.index.minute % freq == 0]\n",
    "    da=pd.concat([da.index.to_series(name='date').astype(str).str.slice(start=0,stop=10),da],axis=1)\n",
    "    mom=da.groupby('date')['close'].shift(0)-da.groupby('date')['close'].shift(n//freq)\n",
    "    acc=mom-mom.shift(1)\n",
    "    signal=pd.Series({}, index=mom.index)\n",
    "    signal[(acc.shift(1)<=0)&(acc>0)]=1\n",
    "    signal[(acc.shift(1)>=0)&(acc<0)]=-1\n",
    "    data = pd.concat([signal.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), signal], axis=1)\n",
    "    signal = data.groupby('date')[0].fillna(method='ffill')\n",
    "    signal = signal.fillna(0)\n",
    "    signal = signal.reindex(close.index, method='ffill')\n",
    "    return signal\n",
    "\n",
    "def acceleration_3(close,open,high,low,size):\n",
    "    freq = 1\n",
    "    n=5\n",
    "    da = close[close.index.minute % freq == 0]\n",
    "    da=pd.concat([da.index.to_series(name='date').astype(str).str.slice(start=0,stop=10),da],axis=1)\n",
    "    mom=da.groupby('date')['close'].shift(0)-da.groupby('date')['close'].shift(n//freq)\n",
    "    acc=mom-mom.shift(1)\n",
    "    signal=pd.Series({}, index=mom.index)\n",
    "    signal[(acc.shift(1)<=0)&(acc>0)]=1\n",
    "    signal[(acc.shift(1)>=0)&(acc<0)]=-1\n",
    "    data = pd.concat([signal.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), signal], axis=1)\n",
    "    signal = data.groupby('date')[0].fillna(method='ffill')\n",
    "    signal = signal.fillna(0)\n",
    "    signal = signal.reindex(close.index, method='ffill')\n",
    "    return signal\n",
    "\n",
    "def acceleration_4(close,open,high,low,size):\n",
    "    freq = 1\n",
    "    n=4\n",
    "    da = close[close.index.minute % freq == 0]\n",
    "    da=pd.concat([da.index.to_series(name='date').astype(str).str.slice(start=0,stop=10),da],axis=1)\n",
    "    mom=da.groupby('date')['close'].shift(0)-da.groupby('date')['close'].shift(n//freq)\n",
    "    acc=mom-mom.shift(1)\n",
    "    signal=pd.Series({}, index=mom.index)\n",
    "    signal[(acc.shift(1)<=0)&(acc>0)]=1\n",
    "    signal[(acc.shift(1)>=0)&(acc<0)]=-1\n",
    "    data = pd.concat([signal.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), signal], axis=1)\n",
    "    signal = data.groupby('date')[0].fillna(method='ffill')\n",
    "    signal = signal.fillna(0)\n",
    "    signal = signal.reindex(close.index, method='ffill')\n",
    "    return signal\n",
    "\n",
    "def EMA_1(close,open,high,low,size):\n",
    "    freq = 1\n",
    "    short=5\n",
    "    long=10\n",
    "    da = close[close.index.minute % freq == 0]\n",
    "    da=pd.concat([da.index.to_series(name='date').astype(str).str.slice(start=0,stop=10),da],axis=1)\n",
    "    short_window=da.groupby('date')['close'].apply(lambda col: col.ewm(span=short//freq, min_periods=short//freq,adjust=False).mean())\n",
    "    long_window=da.groupby('date')['close'].apply(lambda col: col.ewm(span=long//freq, min_periods=long//freq,adjust=False).mean())\n",
    "    dif=short_window-long_window\n",
    "    signal=pd.Series({}, index=short_window.index)\n",
    "    signal[(dif.shift(1)<=0)&(dif>0)]=1\n",
    "    signal[(dif.shift(1)>=0)&(dif<0)]=-1\n",
    "    data = pd.concat([signal.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), signal], axis=1)\n",
    "    signal = data.groupby('date')[0].fillna(method='ffill')\n",
    "    signal = signal.fillna(0)\n",
    "    signal = signal.reindex(close.index, method='ffill')\n",
    "    return signal\n",
    "\n",
    "def EMA_2(close,open,high,low,size):\n",
    "    freq = 1\n",
    "    short=4\n",
    "    long=8\n",
    "    da = close[close.index.minute % freq == 0]\n",
    "    da=pd.concat([da.index.to_series(name='date').astype(str).str.slice(start=0,stop=10),da],axis=1)\n",
    "    short_window=da.groupby('date')['close'].apply(lambda col: col.ewm(span=short//freq, min_periods=short//freq,adjust=False).mean())\n",
    "    long_window=da.groupby('date')['close'].apply(lambda col: col.ewm(span=long//freq, min_periods=long//freq,adjust=False).mean())\n",
    "    dif=short_window-long_window\n",
    "    signal=pd.Series({}, index=short_window.index)\n",
    "    signal[(dif.shift(1)<=0)&(dif>0)]=1\n",
    "    signal[(dif.shift(1)>=0)&(dif<0)]=-1\n",
    "    data = pd.concat([signal.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), signal], axis=1)\n",
    "    signal = data.groupby('date')[0].fillna(method='ffill')\n",
    "    signal = signal.fillna(0)\n",
    "    signal = signal.reindex(close.index, method='ffill')\n",
    "    return signal\n",
    "\n",
    "def chaikin (close,open,high,low,size):\n",
    "    # Set the parameters\n",
    "    n1 = 3\n",
    "    n2 = 23\n",
    "\n",
    "    # Calculate the Chaikin Index\n",
    "    adl = (2*close-low-high)/(high-low)\n",
    "    Chaikin = adl.ewm(span = n1, min_periods = n1-1).mean() - adl.ewm(span = n2, min_periods = n2-1).mean()\n",
    "    \n",
    "    # Calculate the signal\n",
    "    signal = np.sign(Chaikin)\n",
    "    \n",
    "    return signal\n",
    "\n",
    "def money_flow (close,open,high,low,size):\n",
    "    # Set the parameters\n",
    "    n = 100\n",
    "    min_p = 1\n",
    "    upline = 99\n",
    "    downline = 1\n",
    "    \n",
    "    # Calculate the MFI\n",
    "    TypicalPrice = (high+low+close)/3\n",
    "    diffML = TypicalPrice.diff()\n",
    "    positive_ML_mark = diffML.apply(lambda x: 1 if x>0 else 0)\n",
    "    negative_ML_mark = diffML.apply(lambda x: 1 if x<0 else 0)\n",
    "    positive_ML = positive_ML_mark*size\n",
    "    negative_ML = negative_ML_mark*size\n",
    "    p_ML = positive_ML.rolling(window=n, min_periods=min_p).sum()\n",
    "    n_ML = negative_ML.rolling(window=n, min_periods=min_p).sum()\n",
    "    MFI = 100-100/(1+(p_ML/n_ML))\n",
    "   \n",
    "    # Calculate the signal\n",
    "    signal = ((MFI.shift(1)<downline)&(MFI>downline))*1 + ((MFI.shift(1)>upline)&(MFI<upline))*(-1)\n",
    "    \n",
    "    return signal\n",
    "\n",
    "def nvi (close,open,high,low,size):\n",
    "    # Set the parameters and package\n",
    "    initial_nvi = 1000\n",
    "    n = 88751\n",
    "    \n",
    "    # Calculate the Negative Volume Index\n",
    "    diff_size = size.diff()\n",
    "    negative_size_mark = diff_size.apply(lambda x: 1 if x<0 else 0)\n",
    "    multi = (1 + (close-close.shift(1))/close.shift(1))*negative_size_mark\n",
    "    multipler = multi.apply(lambda x: 1 if x==0 else x)\n",
    "    multipler[0] = initial_nvi \n",
    "    nvi = multipler.cumprod()\n",
    "    \n",
    "    # Calculate the signal\n",
    "    ema = nvi.ewm(span = n, min_periods = 1).mean()\n",
    "    signal = ((nvi.shift(1)<ema)&(nvi>ema))*1\n",
    "   \n",
    "    return signal\n",
    "\n",
    "def pvi (close,open,high,low,size):\n",
    "    # Set the parameters and package\n",
    "    initial_pvi = 1000\n",
    "    n=168000\n",
    "    pvi = []\n",
    "    \n",
    "    # Calculate the Negative Volume Index\n",
    "    diff_size = size.diff()\n",
    "    positive_size_mark = diff_size.apply(lambda x: 1 if x>0 else 0)\n",
    "    multi = (1 + (close-close.shift(1))/close.shift(1))*positive_size_mark\n",
    "    multipler = multi.apply(lambda x: 1 if x==0 else x)\n",
    "    multipler[0] = initial_pvi\n",
    "    pvi = multipler.cumprod()\n",
    "    \n",
    "    # Calculate the signal\n",
    "    ema = pvi.ewm(span = n, min_periods = 1).mean()\n",
    "    signal = ((pvi.shift(1)<ema)&(pvi>ema))*1+((pvi.shift(1)>ema)&(pvi<ema))*(-1)\n",
    "   \n",
    "    return signal\n",
    "\n",
    "def fast_stochastic_1(close, open, high, low, size):\n",
    "    # par = parameter\n",
    "    para1 =8606\n",
    "    para2 = 2781\n",
    "    para3 = 424\n",
    "    high_temp = pd.concat([high.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), high], axis=1)\n",
    "    low_temp = pd.concat([low.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), low], axis=1)\n",
    "    hh = high_temp.groupby('date').high.rolling(window=para1, min_periods=1).max()\n",
    "    ll = low_temp.groupby('date').low.rolling(window=para2, min_periods=1).min()\n",
    "    hh.index = ll.index = close.index\n",
    "    k_value_t = (close - ll) / (hh - ll)\n",
    "\n",
    "    k_value_t_temp = pd.concat(\n",
    "        [k_value_t.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), k_value_t],\n",
    "        axis=1)\n",
    "    k_value_t_temp.columns = ['date', 'close']\n",
    "    k_value_t_1 = k_value_t_temp.groupby('date')['close'].shift(1)\n",
    "    k_value_t_1.index = close.index\n",
    "\n",
    "    # k_value_t_1 = k_value_t.shift(1)\n",
    "    # high_temp = pd.concat([high.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), high], axis=1)\n",
    "    d_value_t = k_value_t_temp.groupby('date').close.rolling(window=para3, min_periods=1).mean()\n",
    "    d_value_t.index = close.index\n",
    "    # d_value_t = k_value_t.rolling(window=700, min_periods=1).mean()\n",
    "\n",
    "    #     d_temp=pd.concat([close.index.to_series(name='date').astype(str).str.slice(start=0,stop=10),k_value_t],axis=1)\n",
    "    #     print(d_temp)\n",
    "    #     d_value_t = k_value_t.groupby('date').k_value_t.rolling(window=500,min_periods=1).mean()\n",
    "    #     d_value_t.index = close.index\n",
    "    #     d_temp.columns = ['k_value_t']\n",
    "\n",
    "    signal = ((k_value_t_1 < d_value_t) & (k_value_t > d_value_t)) * (1) + (\n",
    "            (k_value_t_1 > d_value_t) & (k_value_t < d_value_t)) * (-1)\n",
    "    # signal = -signal\n",
    "    return signal\n",
    "\n",
    "\n",
    "def fast_stochastic_2(close, open, high, low, size):\n",
    "    # par = parameter\n",
    "    para1 =8600\n",
    "    para2 = 2781\n",
    "    para3 = 424\n",
    "    high_temp = pd.concat([high.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), high], axis=1)\n",
    "    low_temp = pd.concat([low.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), low], axis=1)\n",
    "    hh = high_temp.groupby('date').high.rolling(window=para1, min_periods=1).max()\n",
    "    ll = low_temp.groupby('date').low.rolling(window=para2, min_periods=1).min()\n",
    "    hh.index = ll.index = close.index\n",
    "    k_value_t = (close - ll) / (hh - ll)\n",
    "\n",
    "    k_value_t_temp = pd.concat(\n",
    "        [k_value_t.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), k_value_t],\n",
    "        axis=1)\n",
    "    k_value_t_temp.columns = ['date', 'close']\n",
    "    k_value_t_1 = k_value_t_temp.groupby('date')['close'].shift(1)\n",
    "    k_value_t_1.index = close.index\n",
    "\n",
    "    # k_value_t_1 = k_value_t.shift(1)\n",
    "    # high_temp = pd.concat([high.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), high], axis=1)\n",
    "    d_value_t = k_value_t_temp.groupby('date').close.rolling(window=para3, min_periods=1).mean()\n",
    "    d_value_t.index = close.index\n",
    "    # d_value_t = k_value_t.rolling(window=700, min_periods=1).mean()\n",
    "\n",
    "    #     d_temp=pd.concat([close.index.to_series(name='date').astype(str).str.slice(start=0,stop=10),k_value_t],axis=1)\n",
    "    #     print(d_temp)\n",
    "    #     d_value_t = k_value_t.groupby('date').k_value_t.rolling(window=500,min_periods=1).mean()\n",
    "    #     d_value_t.index = close.index\n",
    "    #     d_temp.columns = ['k_value_t']\n",
    "\n",
    "    signal = ((k_value_t_1 < d_value_t) & (k_value_t > d_value_t)) * (1) + (\n",
    "            (k_value_t_1 > d_value_t) & (k_value_t < d_value_t)) * (-1)\n",
    "    # signal = -signal\n",
    "    return signal\n",
    "\n",
    "\n",
    "def fast_stochastic_3(close, open, high, low, size):\n",
    "    # par = parameter\n",
    "    para1 =8606\n",
    "    para2 = 2780\n",
    "    para3 = 424\n",
    "    high_temp = pd.concat([high.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), high], axis=1)\n",
    "    low_temp = pd.concat([low.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), low], axis=1)\n",
    "    hh = high_temp.groupby('date').high.rolling(window=para1, min_periods=1).max()\n",
    "    ll = low_temp.groupby('date').low.rolling(window=para2, min_periods=1).min()\n",
    "    hh.index = ll.index = close.index\n",
    "    k_value_t = (close - ll) / (hh - ll)\n",
    "\n",
    "    k_value_t_temp = pd.concat(\n",
    "        [k_value_t.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), k_value_t],\n",
    "        axis=1)\n",
    "    k_value_t_temp.columns = ['date', 'close']\n",
    "    k_value_t_1 = k_value_t_temp.groupby('date')['close'].shift(1)\n",
    "    k_value_t_1.index = close.index\n",
    "\n",
    "    # k_value_t_1 = k_value_t.shift(1)\n",
    "    # high_temp = pd.concat([high.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), high], axis=1)\n",
    "    d_value_t = k_value_t_temp.groupby('date').close.rolling(window=para3, min_periods=1).mean()\n",
    "    d_value_t.index = close.index\n",
    "    # d_value_t = k_value_t.rolling(window=700, min_periods=1).mean()\n",
    "\n",
    "    #     d_temp=pd.concat([close.index.to_series(name='date').astype(str).str.slice(start=0,stop=10),k_value_t],axis=1)\n",
    "    #     print(d_temp)\n",
    "    #     d_value_t = k_value_t.groupby('date').k_value_t.rolling(window=500,min_periods=1).mean()\n",
    "    #     d_value_t.index = close.index\n",
    "    #     d_temp.columns = ['k_value_t']\n",
    "\n",
    "    signal = ((k_value_t_1 < d_value_t) & (k_value_t > d_value_t)) * (1) + (\n",
    "            (k_value_t_1 > d_value_t) & (k_value_t < d_value_t)) * (-1)\n",
    "    # signal = -signal\n",
    "    return signal\n",
    "\n",
    "\n",
    "def fast_stochastic_4(close, open, high, low, size):\n",
    "    # par = parameter\n",
    "    para1 =8600\n",
    "    para2 = 2780\n",
    "    para3 = 424\n",
    "    high_temp = pd.concat([high.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), high], axis=1)\n",
    "    low_temp = pd.concat([low.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), low], axis=1)\n",
    "    hh = high_temp.groupby('date').high.rolling(window=para1, min_periods=1).max()\n",
    "    ll = low_temp.groupby('date').low.rolling(window=para2, min_periods=1).min()\n",
    "    hh.index = ll.index = close.index\n",
    "    k_value_t = (close - ll) / (hh - ll)\n",
    "\n",
    "    k_value_t_temp = pd.concat(\n",
    "        [k_value_t.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), k_value_t],\n",
    "        axis=1)\n",
    "    k_value_t_temp.columns = ['date', 'close']\n",
    "    k_value_t_1 = k_value_t_temp.groupby('date')['close'].shift(1)\n",
    "    k_value_t_1.index = close.index\n",
    "\n",
    "    # k_value_t_1 = k_value_t.shift(1)\n",
    "    # high_temp = pd.concat([high.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), high], axis=1)\n",
    "    d_value_t = k_value_t_temp.groupby('date').close.rolling(window=para3, min_periods=1).mean()\n",
    "    d_value_t.index = close.index\n",
    "    # d_value_t = k_value_t.rolling(window=700, min_periods=1).mean()\n",
    "\n",
    "    #     d_temp=pd.concat([close.index.to_series(name='date').astype(str).str.slice(start=0,stop=10),k_value_t],axis=1)\n",
    "    #     print(d_temp)\n",
    "    #     d_value_t = k_value_t.groupby('date').k_value_t.rolling(window=500,min_periods=1).mean()\n",
    "    #     d_value_t.index = close.index\n",
    "    #     d_temp.columns = ['k_value_t']\n",
    "\n",
    "    signal = ((k_value_t_1 < d_value_t) & (k_value_t > d_value_t)) * (1) + (\n",
    "            (k_value_t_1 > d_value_t) & (k_value_t < d_value_t)) * (-1)\n",
    "    # signal = -signal\n",
    "    return signal\n",
    "\n",
    "\n",
    "def slow_stochastic(close, open, high, low, size):\n",
    "    para1 = 2837\n",
    "    para2 = 3483\n",
    "    para3 = 4547\n",
    "    para4 = 9497\n",
    "    high_temp = pd.concat([high.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), high], axis=1)\n",
    "    low_temp = pd.concat([low.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), low], axis=1)\n",
    "\n",
    "    hh = high_temp.groupby('date').high.rolling(window=para1, min_periods=1).max()\n",
    "    ll = low_temp.groupby('date').low.rolling(window=para2, min_periods=1).min()\n",
    "    hh.index = ll.index = close.index\n",
    "    k_value_t = (close - ll) / (hh - ll)\n",
    "\n",
    "    k_value_t_temp = pd.concat(\n",
    "        [k_value_t.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), k_value_t],\n",
    "        axis=1)\n",
    "    k_value_t_temp.columns = ['date', 'close']\n",
    "    k_t_1 = k_value_t_temp.groupby('date')['close'].shift(1)\n",
    "    k_t = k_value_t_temp.groupby('date').close.rolling(window=para3, min_periods=1).mean()\n",
    "    k_t_1.index = k_t.index = close.index\n",
    "\n",
    "    k_t_temp = pd.concat(\n",
    "        [k_t.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), k_t],\n",
    "        axis=1)\n",
    "    d_t = k_t_temp.groupby('date').close.rolling(window=para4, min_periods=1).mean()\n",
    "    d_t.index = close.index\n",
    "\n",
    "    signal = ((k_t_1 < d_t) & (k_t > d_t)) * (1) + ((k_t_1 > d_t) & (k_t < d_t)) * (-1)\n",
    "\n",
    "    return signal\n",
    "\n",
    "\n",
    "def RSI_1(close, open, high, low, size):\n",
    "    para1 = 8469\n",
    "    para2 = 341\n",
    "    para3 = 6013\n",
    "    para4 = 459\n",
    "\n",
    "    close_temp = pd.concat([close.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), close], axis=1)\n",
    "    difference = close_temp.groupby('date').close.diff()\n",
    "\n",
    "    up = difference.apply(lambda x: 1 if x > 0 else 0)\n",
    "    down = difference.apply(lambda x: 1 if x < 0 else 0)\n",
    "\n",
    "    up_temp = pd.concat([up.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), up], axis=1)\n",
    "    up_count = up_temp.groupby('date').close.rolling(window=para1, min_periods=1).sum()\n",
    "    up_count.index = close.index\n",
    "\n",
    "    down_temp = pd.concat([down.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), down], axis=1)\n",
    "    down_count = down_temp.groupby('date').close.rolling(window=para2, min_periods=1).sum()\n",
    "    down_count.index = close.index\n",
    "    # print(down_count.index)\n",
    "\n",
    "    down_count = down_count * (-1)\n",
    "\n",
    "    up_count_temp = pd.concat([up_count.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), up_count],\n",
    "                              axis=1)\n",
    "    down_count_temp = pd.concat(\n",
    "        [down_count.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), down_count],\n",
    "        axis=1)\n",
    "\n",
    "    up_sma = up_count_temp.groupby('date').close.rolling(window=para3, min_periods=1).mean()\n",
    "    down_sma = down_count_temp.groupby('date').close.rolling(window=para4, min_periods=1).mean()\n",
    "    up_sma.index = down_sma.index = close.index\n",
    "\n",
    "    print(down_sma[down_sma == 0])\n",
    "    rsi_value = 100 - 100 / (1 + up_sma / down_sma)\n",
    "\n",
    "    print(rsi_value)\n",
    "\n",
    "    rsi_value_temp = pd.concat(\n",
    "        [rsi_value.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), down_count],\n",
    "        axis=1)\n",
    "    rsi_value_1 = rsi_value_temp.groupby('date')['close'].shift(1)\n",
    "    rsi_value_1.index = close.index\n",
    "\n",
    "    signal = ((rsi_value_1 <= 20) & (rsi_value > 20)) * (1) + ((rsi_value_1 >= 80) & (rsi_value < 80)) * (-1)\n",
    "    # print(len(signal[signal ==1]))\n",
    "    return signal\n",
    "\n",
    "\n",
    "def RSI_2(close, open, high, low, size):\n",
    "    para1 = 8008\n",
    "    para2 = 5933\n",
    "    para3 = 4670\n",
    "    para4 = 997\n",
    "\n",
    "    close_temp = pd.concat([close.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), close], axis=1)\n",
    "    difference = close_temp.groupby('date').close.diff()\n",
    "\n",
    "    up = difference.apply(lambda x: 1 if x > 0 else 0)\n",
    "    down = difference.apply(lambda x: 1 if x < 0 else 0)\n",
    "\n",
    "    up_temp = pd.concat([up.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), up], axis=1)\n",
    "    up_count = up_temp.groupby('date').close.rolling(window=para1, min_periods=1).sum()\n",
    "    up_count.index = close.index\n",
    "\n",
    "    down_temp = pd.concat([down.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), down], axis=1)\n",
    "    down_count = down_temp.groupby('date').close.rolling(window=para2, min_periods=1).sum()\n",
    "    down_count.index = close.index\n",
    "    # print(down_count.index)\n",
    "\n",
    "    down_count = down_count * (-1)\n",
    "\n",
    "    up_count_temp = pd.concat([up_count.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), up_count],\n",
    "                              axis=1)\n",
    "    down_count_temp = pd.concat(\n",
    "        [down_count.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), down_count],\n",
    "        axis=1)\n",
    "\n",
    "    up_sma = up_count_temp.groupby('date').close.rolling(window=para3, min_periods=1).mean()\n",
    "    down_sma = down_count_temp.groupby('date').close.rolling(window=para4, min_periods=1).mean()\n",
    "    up_sma.index = down_sma.index = close.index\n",
    "\n",
    "    print(down_sma[down_sma == 0])\n",
    "    rsi_value = 100 - 100 / (1 + up_sma / down_sma)\n",
    "\n",
    "    print(rsi_value)\n",
    "\n",
    "    rsi_value_temp = pd.concat(\n",
    "        [rsi_value.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), down_count],\n",
    "        axis=1)\n",
    "    rsi_value_1 = rsi_value_temp.groupby('date')['close'].shift(1)\n",
    "    rsi_value_1.index = close.index\n",
    "\n",
    "    signal = ((rsi_value_1 <= 10) & (rsi_value > 10)) * (1) + ((rsi_value_1 >= 90) & (rsi_value < 90)) * (-1)\n",
    "    # print(len(signal[signal ==1]))\n",
    "    return signal\n",
    "\n",
    "\n",
    "def RSI_3(close, open, high, low, size):\n",
    "    para1 = 2816\n",
    "    para2 = 1204\n",
    "    para3 = 2314\n",
    "    para4 = 820\n",
    "\n",
    "    close_temp = pd.concat([close.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), close], axis=1)\n",
    "    difference = close_temp.groupby('date').close.diff()\n",
    "\n",
    "    up = difference.apply(lambda x: 1 if x > 0 else 0)\n",
    "    down = difference.apply(lambda x: 1 if x < 0 else 0)\n",
    "\n",
    "    up_temp = pd.concat([up.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), up], axis=1)\n",
    "    up_count = up_temp.groupby('date').close.rolling(window=para1, min_periods=1).sum()\n",
    "    up_count.index = close.index\n",
    "\n",
    "    down_temp = pd.concat([down.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), down], axis=1)\n",
    "    down_count = down_temp.groupby('date').close.rolling(window=para2, min_periods=1).sum()\n",
    "    down_count.index = close.index\n",
    "    # print(down_count.index)\n",
    "\n",
    "    down_count = down_count * (-1)\n",
    "\n",
    "    up_count_temp = pd.concat([up_count.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), up_count],\n",
    "                              axis=1)\n",
    "    down_count_temp = pd.concat(\n",
    "        [down_count.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), down_count],\n",
    "        axis=1)\n",
    "\n",
    "    up_sma = up_count_temp.groupby('date').close.rolling(window=para3, min_periods=1).mean()\n",
    "    down_sma = down_count_temp.groupby('date').close.rolling(window=para4, min_periods=1).mean()\n",
    "    up_sma.index = down_sma.index = close.index\n",
    "\n",
    "    print(down_sma[down_sma == 0])\n",
    "    rsi_value = 100 - 100 / (1 + up_sma / down_sma)\n",
    "\n",
    "    print(rsi_value)\n",
    "\n",
    "    rsi_value_temp = pd.concat(\n",
    "        [rsi_value.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), down_count],\n",
    "        axis=1)\n",
    "    rsi_value_1 = rsi_value_temp.groupby('date')['close'].shift(1)\n",
    "    rsi_value_1.index = close.index\n",
    "\n",
    "    signal = ((rsi_value_1 <= 15) & (rsi_value > 15)) * (1) + ((rsi_value_1 >= 85) & (rsi_value < 85)) * (-1)\n",
    "    # print(len(signal[signal ==1]))\n",
    "    return signal\n",
    "\n",
    "\n",
    "def MARSI_1(close, open, high, low, size):\n",
    "    para1 = 6482\n",
    "    para2 = 9145\n",
    "    para3 = 348\n",
    "    para4 = 2701\n",
    "    para5 = 4672\n",
    "    close_temp = pd.concat([close.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), close], axis=1)\n",
    "    difference = close_temp.groupby('date').close.diff()\n",
    "    up = difference.apply(lambda x: 1 if x > 0 else 0)\n",
    "    down = difference.apply(lambda x: 1 if x < 0 else 0)\n",
    "    up_temp = pd.concat([up.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), up], axis=1)\n",
    "    up_count = up_temp.groupby('date').close.rolling(window=para1, min_periods=1).sum()\n",
    "    up_count.index = close.index\n",
    "    # print('sdfghjkhg',up_count)\n",
    "    down_temp = pd.concat([down.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), down], axis=1)\n",
    "    down_count = down_temp.groupby('date').close.rolling(window=para2, min_periods=1).sum()\n",
    "    down_count.index = close.index\n",
    "    # print(down_count.index)\n",
    "    down_count = down_count * (-1)\n",
    "    up_count_temp = pd.concat([up_count.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), up_count],\n",
    "                              axis=1)\n",
    "    down_count_temp = pd.concat(\n",
    "        [down_count.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), down_count],\n",
    "        axis=1)\n",
    "    up_sma = up_count_temp.groupby('date').close.rolling(window=para3, min_periods=1).mean()\n",
    "    down_sma = down_count_temp.groupby('date').close.rolling(window=para4, min_periods=1).mean()\n",
    "    up_sma.index = down_sma.index = close.index\n",
    "    # print(down_sma[down_sma == 0])\n",
    "    rsi_value = 100 - 100 / (1 + up_sma / down_sma)\n",
    "    rsi_value_temp = pd.concat(\n",
    "        [rsi_value.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), rsi_value],\n",
    "        axis=1)\n",
    "    marsi = rsi_value_temp.groupby('date').close.rolling(window=para5, min_periods=1).mean()\n",
    "    marsi.index = close.index\n",
    "    marsi_temp = pd.concat([marsi.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), marsi],\n",
    "                           axis=1)\n",
    "    marsi_1 = marsi_temp.groupby('date')['close'].shift(1)\n",
    "    marsi_1.index = close.index\n",
    "    signal = ((marsi_1 <= 30) & (marsi > 30)) * (1) + ((marsi_1 >= 70) & (marsi < 70)) * (-1)\n",
    "    return signal\n",
    "\n",
    "\n",
    "def MARSI_2(close, open, high, low, size):\n",
    "    para1 = 5434\n",
    "    para2 = 9886\n",
    "    para3 = 5987\n",
    "    para4 = 4685\n",
    "    para5 = 9077\n",
    "    close_temp = pd.concat([close.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), close], axis=1)\n",
    "    difference = close_temp.groupby('date').close.diff()\n",
    "    up = difference.apply(lambda x: 1 if x > 0 else 0)\n",
    "    down = difference.apply(lambda x: 1 if x < 0 else 0)\n",
    "    up_temp = pd.concat([up.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), up], axis=1)\n",
    "    up_count = up_temp.groupby('date').close.rolling(window=para1, min_periods=1).sum()\n",
    "    up_count.index = close.index\n",
    "    # print('sdfghjkhg',up_count)\n",
    "    down_temp = pd.concat([down.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), down], axis=1)\n",
    "    down_count = down_temp.groupby('date').close.rolling(window=para2, min_periods=1).sum()\n",
    "    down_count.index = close.index\n",
    "    # print(down_count.index)\n",
    "    down_count = down_count * (-1)\n",
    "    up_count_temp = pd.concat([up_count.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), up_count],\n",
    "                              axis=1)\n",
    "    down_count_temp = pd.concat(\n",
    "        [down_count.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), down_count],\n",
    "        axis=1)\n",
    "    up_sma = up_count_temp.groupby('date').close.rolling(window=para3, min_periods=1).mean()\n",
    "    down_sma = down_count_temp.groupby('date').close.rolling(window=para4, min_periods=1).mean()\n",
    "    up_sma.index = down_sma.index = close.index\n",
    "    # print(down_sma[down_sma == 0])\n",
    "    rsi_value = 100 - 100 / (1 + up_sma / down_sma)\n",
    "    rsi_value_temp = pd.concat(\n",
    "        [rsi_value.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), rsi_value],\n",
    "        axis=1)\n",
    "    marsi = rsi_value_temp.groupby('date').close.rolling(window=para5, min_periods=1).mean()\n",
    "    marsi.index = close.index\n",
    "    marsi_temp = pd.concat([marsi.index.to_series(name='date').astype(str).str.slice(start=0, stop=10), marsi],\n",
    "                           axis=1)\n",
    "    marsi_1 = marsi_temp.groupby('date')['close'].shift(1)\n",
    "    marsi_1.index = close.index\n",
    "    signal = ((marsi_1 <= 20) & (marsi > 20)) * (1) + ((marsi_1 >= 80) & (marsi < 80)) * (-1)\n",
    "    return signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_tw_top50 = ['2317', '2330', '2337', '2492', '2344', '2303', '2409', '2891', '2327', '3481', '2448', '6153',\n",
    "                   '2408', '2883', '2888', '2353', '2313', '2371', '2377', '2456', '2002', '3026', '2886', '3037',\n",
    "                   '2481', '2884', '1101', '2345', '3406', '3231', '2882', '2885', '1605', '6456', '3443', '2892',\n",
    "                   '2881', '2376', '2887', '2027', '2412', '2049', '2454', '3016', '8163', '3019', '2455', '2367',\n",
    "                   '2323', '1216', ]\n",
    "stocks_tw_top100 = ['2317', '2330', '2337', '2492', '2344', '2303', '2409', '2891', '2327', '3481', '2448', '6153',\n",
    "                    '2408', '2883', '2888', '2353', '2313', '2371', '2377', '2456', '2002', '3026', '2886', '3037',\n",
    "                    '2481', '2884', '1101', '2345', '3406', '3231', '2882', '2885', '1605', '6456', '3443', '2892',\n",
    "                    '2881', '2376', '2887', '2027', '2412', '2049', '2454', '3016', '8163', '3019', '2455', '2367',\n",
    "                    '2323', '1216', '1314', '2308', '0050', '2498', '2356', '1402', '3673', '4938', '2834', '1102',\n",
    "                    '2474', '2478', '1301', '5880', '1326', '2439', '3090', '2324', '2603', '3532', '2890', '2382',\n",
    "                    '6116', '1303', '1312', '2880', '3504', '2375', '2301', '6176', '3035', '3661', '5871', '2610',\n",
    "                    '4958', '2340', '6120', '3059', '9958', '2014', '2823', '3034', '6269', '9904', '2347', '2105',\n",
    "                    '2349', '2618', '3596', '0058']\n",
    "stocks_tw = ['2327']\n",
    "strategy = ['MACD_1']#,'MACD_2','acceleration_1','acceleration_2','acceleration_3','acceleration_4','EMA_1','EMA_2']\n",
    "stockDataDir = '/Users/kuen/Desktop/CTA/data/'\n",
    "cols = [\"date\", \"time\", \"lastPx\", \"size\", \"volume\", \"SP5\", \"SP4\", \"SP3\", \"SP2\", \"SP1\", \"BP1\", \"BP2\", \"BP3\", \"BP4\",\n",
    "        \"BP5\", \"SV5\", \"SV4\", \"SV3\", \"SV2\", \"SV1\", \"BV1\", \"BV2\", \"BV3\", \"BV4\", \"BV5\"]\n",
    "close = pd.DataFrame(columns=stocks_tw)\n",
    "size = pd.DataFrame(columns=stocks_tw)\n",
    "volume = pd.DataFrame(columns=stocks_tw)\n",
    "\n",
    "ret=pd.DataFrame(None,index=stocks_tw,columns=strategy)\n",
    "drawdown=pd.DataFrame(None,index=stocks_tw,columns=strategy)\n",
    "# max position 1 lot. signal 0, position doesn't change\n",
    "class backtest(object):\n",
    "    def __init__(self,data,signal):\n",
    "\n",
    "        signal[signal.isna()]=0\n",
    "        self.data=data\n",
    "        self.signal=signal\n",
    "        self.data['signal']=signal\n",
    "        signal_l = list(self.data.signal)\n",
    "        position = [data.signal[0]]\n",
    "        time=list(data.index.strftime(\"%Y-%m-%d %H:%M\"))\n",
    "        for i in range(1,len(data),1):\n",
    "            if  ('13:21' in time[i]) or ('13:22' in time[i]) or ('13:23' in time[i]) or \\\n",
    "            ('13:24' in time[i]) or ('13:25' in time[i]):\n",
    "                position.append(0)\n",
    "                continue\n",
    "#             elif signal_l[i]==0: position.append(position[i-1])\n",
    "            else: position.append(signal_l[i])\n",
    "        data['position'] = position\n",
    "        data['position'] = data['position']*1000\n",
    "        data['trades']=data.position.diff()\n",
    "        data.trades[0]=data.signal[0]\n",
    "        data['balance']=(-data.nexttick_px*data.trades-abs(0.00095*data.nexttick_px*data.trades)).cumsum()\n",
    "        data['value']=data.balance+data.position*data.close\n",
    "        data.value=data.value.fillna(method='ffill')\n",
    "        self.data=data\n",
    "    def wealth(self):\n",
    "        ret=self.data.value[-1]\n",
    "        return ret\n",
    "    def maxdrawdown(self):\n",
    "        drawdowns = []\n",
    "        max_so_far = self.data.value[0]\n",
    "        for i in range(len(self.data.value)):\n",
    "            if self.data.value[i] > max_so_far:\n",
    "                drawdown = 0\n",
    "                drawdowns.append(drawdown)\n",
    "                max_so_far = self.data.value[i]\n",
    "            else:\n",
    "                drawdown = max_so_far - self.data.value[i]\n",
    "                drawdowns.append(drawdown)\n",
    "        return max(drawdowns)\n",
    "    def pnl_day(self):\n",
    "        pnl=self.data.value.resample('D').last()-self.data.value.resample('D').first()\n",
    "        return pnl\n",
    "def test_all():\n",
    "    for i in range(len(stocks_tw)):\n",
    "        dff=clean_data(i)\n",
    "        for j in range(len(strategy)):\n",
    "\n",
    "                fac=eval(strategy[j])(dff.close,dff.open,dff.high,dff.low,dff['size'])\n",
    "                a=backtest(dff,fac)\n",
    "                ret.iloc[i,j]=a.wealth()\n",
    "                drawdown.iloc[i,j]=a.maxdrawdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2327\n",
      "Data(First file) for 2327 loaded.\n",
      "Data(Second file) for 2327 loaded.\n"
     ]
    }
   ],
   "source": [
    "test_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
